## Page 1

   IT & Future Strategy
주목받는 인공지능 (AI) 
9대 핵심 기술 분석 및 주요 시사점
                                                    제1호(2021. 1. 15.)
  
목 차 
Ⅰ. 빠르게 진화하고 있는 인공지능 / 1
Ⅱ. 주목받는 인공지능 9대 핵심 기술 / 4
Ⅲ. 인공지능 9대 핵심 기술로 본 주요 시사점 / 18


## Page 2

「IT & Future Strategy(IF Strategy) 」 보고서 는 21세기 한국사회의 주요 패러다임  변화
를 분석하고 이를 토대로 미래 지능화 시대의 주요 이슈를 전망, IT를 통한 해결방
안을 모색하기 위해 한국지능정보사회진흥원 (NIA)에서 기획, 발간하는 보고서입니 다.
「IF Strategy 」는 미래의 ‘만약을 대비한 전략’을 담은 보고서를 의미합니다 .
NIA의 승인 없이 본 보고서의 무단전재나 복제를 금하며 , 인용하실 때는 반
드시 NIA, 「IT & Future Strategy 보고서 」라고 밝혀주시기 바랍니다 . 보고서 
내용에 대한 문의나 제안은 아래 연락처로 해 주시기 바랍니다 . 
▶발행인 : 문 용 식
▶작  성  
 - 한국지능정보사회진흥원 (NIA) 정책본부 AI·미래전략센터
 우상근 책임연구원 (053-230-1290, sangkeun.woo@nia.or.kr )
     김예지 연구원 (053-230-1286, yeji.gim@nia.or.kr)
▶보고서 온라인 서비스 
 - www.nia.or.kr
 

## Page 3

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 3
IT & Future Strategy(1 호)  2020. 1
◇ 주요 기술 등장에 따른 인공지능 생태계의 변화
  o 2012년 개최된 이미지넷 챌린지는 딥러닝 부활의 신호탄이 되었으며 , 
이후 이미지 및 자연어처리 분야에서 인공지능이 활용 
  o 인공지능은 알파고 쇼크 이후 산업, 기술계를 넘어 정치·사회·문화 
등 사회 전반으로의 영향력이 확산
◇ 한계를 극복하며 진화하는 인공지능 핵심 기술
  o 인공지능 기술이 사회 전반의 혁신을 이룰 것이라는 기대에 반해 현재 
인공지능의 구현 기능은 여전히 많은 한계 보유 
  - 민감한 정보에 대한 데이터 이동 문제, 직관적 인식을 넘어선 인과관
계 이해 부족, 전처리 과정의 비용·시간 제약 등이 여전히 존재 
  o 인공지능 개발의 한계를 극복하기 위해 전 세계적으로 다양한 측면의 
연구가 동시다발적으로 이루어지고 있는 상황
  - 제도적 한계를 극복하기 위해 개인정보가 보호되고 , 분산된 환경에서 
학습할 수 있는 연합학습 연구 등 진행
  - 딥러닝이 맥락 및 인과관계를 효과적으로 이해할 수 있도록 시스템 2 
AI 개발이 이루어지고 있으며 , 자기지도학습 모델 개발을 통한 언어 
및 이미지 분야에서 인공지능 성능 대폭 개선 중 

## Page 4

◇ 인공지능 활성화를 위한 주요 시사점 
  o 우리나라도 최신 인공지능 트렌드를 파악하여 , 실제 산업에 적용해 효
과를 발휘할 수 있는 기술 선정 및 조기 검증 필요 
  - 실제 산업에 적용할 수 있는 新기술을 선정하여 , 응용 서비스 활성화와 
기술 경쟁력을 확보할 수 있는 방안 마련 필요
  o 빠르게 발전하는 인공지능 기술을 산업 내 적절하게 적용하고 활성화
하기 위해 인공지능 핵심 기술 분석 및 시사점 도출
  - 글로벌 주요 언론, 컨설팅 기업의 자료와 인공지능 주요 인사의 인터
뷰 내용 등을 기반으로 향후 주목하는 인공지능 기술 도출  
  - 9대 기술을 통해 모델의 대형화 ·경량화 , 응용서비스 활성화 지원 기
술 현황, 우수인재의 중요성 등의 시사점 도출


## Page 5

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 1
IT & Future Strategy(1 호)  2020. 1     빠르게 진화하고 있는 인공지능Ⅰ
□ 주요 기술 등장에 따른 인공지능 생태계의 변화
o2012년 개최된 이미지넷 챌린지는 딥러닝 부활의 신호탄이 되
었으며 ,이후 이미지 및 자연어처리 분야에서 인공지능이 활용
-2012년 이미지 분류 분야에 딥러닝 알고리즘을 적용하여 ,
오류율을 급격히 개선하여 기술 커뮤니티의 이목을 집중
-이후 이미지 처리뿐만 아니라 ,자연어처리 분야에도 딥러닝의 
적용이 새로운 과제가 되어 지속적으로 발전하고 있음
o인공지능은 알파고 쇼크 이후 산업 ,기술계를 넘어 정치·사회·
문화 등 사회 전반으로의 영향력이 확산
-2016년 알파고 쇼크 이후 전 세계는 딥러닝의 가능성이 알려
지면서 ,기계와 인간 간 역할의 변화에 관심을 가지기 시작
-이후 정치 ‧
경제 ‧
사회 ‧
문화 등 각 분야에 인공지능 도입으로 
인한 파급효과를 연구하는 등 각국의 핵심전략으로 자리 잡음
o최근 인공지능은 기술적 제약을 지속적으로 극복하고 ,빠르게 
진화하고 있는 단계로 향후 비약적인 발전이 기대됨
< 인공지능 분야 주요 기술 등장 > 


## Page 6

2 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
□ 한계를 극복하며 진화하는 인공지능 핵심 기술
o인공지능 기술이 사회 전반의 혁신을 이룰 것이라는 기대에 
반해 현재 인공지능의 구현 기능은 여전히 많은 한계 보유
-딥러닝은 데이터를 이동 ‧
통합하여 학습이 필요한 반면 ,민감한 
정보에 대한 데이터는 통합이 어려워 학습에 어려움 존재
-현재의 딥러닝은 직관적인 사물인식 등의 과제는 원활히 수행
하나 ,맥락을 파악하고 인과관계를 이해하는 기능은 부족
-여전히 데이터 라벨링에 의존하는 지도학습이 주류이므로 전
처리를 위한 비용 ‧
시간의 제약이 많은 상황
o인공지능 개발의 한계를 극복하기 위해 전 세계적으로 다양한 
측면의 연구가 동시다발적으로 이루어지고 있는 상황
-제도적 한계를 극복하기 위해 개인정보가 보호되고 ,분산된 
환경에서 학습할 수 있는 연합학습 ,엣지 AI등 연구 활발
-딥러닝이 맥락 및 인과관계를 효과적으로 이해할 수 있도록 요
슈아 벤지오 교수가 강조하는 시스템 2AI1)모델 연구 진행
-얀 르쿤 교수가 명명한 자기지도학습 2)(비지도학습 )으로 언어모
델이 개발되고 있고 ,이미지 분야에서도 큰 폭의 성능 개선 중
    ※ 제프리 힌튼 교수는 이미지 분류 분야에 자기지도학습을 적용하여 , 이미지넷 
데이터 Top-1 정확도에서 지도학습과 대등한 성능 달성(구글, ‘20.6)
o우리나라도 최신 인공지능 트렌드를 파악하여 ,실제 산업에 
적용해 효과를 발휘할 수 있는 기술 선정 및 조기 검증 필요
-실제 산업에 적용할 수 있는 新기술을 선정하여 ,응용 서비스 
활성화와 기술 경쟁력을 확보할 수 있는 방안 마련 필요
1) 시스템 2 AI : 단순 사물 인식(분류) 등을 넘어 맥락을 이해하고 , 인과관계를 이해하는 AI
2) 자기지도학습 : 입력 값의 일정 부분으로 입력 값의 다른 부분을 예측하며 , 입력 값의 자체로 지도
(supervision) 를 만들어 학습

## Page 7

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 3
IT & Future Strategy(1 호)  2020. 1□ 인공지능 대가들이 말하는 인공지능 발전 방향
“ GPT-3 가 어느 정도 자연스러운 문장을 구사하지만 여전
히 인간의 뉴런에 비해 매우 적은 규모이므로 데이터 , 신
경망에서 더욱 큰 규모의 증가가 이루어지면 인간의 이성
적 사고와 유사한 구현이 가능해질 것 ” 
   (2020.11, MIT Technology Review)
-토론토 대학 교수, 구글 AI 총괄
-신경망 구축의 초기 단계를 이끌고 , 2012년 이미지넷 챌린지 (ILSVRC) 에서 우승
하며 딥러닝 시대 개척제프리 힌튼
(Geoffrey Hinton)
“ 오늘날 딥러닝의 한계는 지도학습의 한계를 의미, 자기지
도학습이 이를 극복할 수 있는 혁명을 일으킬 것이며 이를 
통해 기계는 과도한 학습의 의존성을 줄이고 세상에 대한 
모델들 , 즉 상식을 습득할 수 있을 것 ”
 (2020.2, AAAI 2020)
-뉴욕 대학 교수, 페이스북 수석 AI 엔지니어
- 1980년대 컨볼루션 신경망 (Convolution Neural Network, CNN) 개념
을 최초 발표얀 르쿤
(Yann LeCun)
“ 새로운 상황들이 학습분포에 일어날 확률이 0이라도 인
간은 이런 작업을 잘 해내지만 딥러닝은 불가능 , 따라서 
인과 관계를 접목해 보다 발전된 '학습 외 분포'를 일반화
하는 것이 중요 ”
(2020.2, NeurIPS 2019)
-몬트리올 대학 교수
-신경망 언어모델 (NPLM) 을 통해 딥러닝 자연어처리의 핵심인 임
베딩을 창안요슈아 벤지오
(Yoshua Bengio)
“ 범용 인공지능 (AGI) 에 도달하기 위한 핵심은 전이학습 , 
전이 학습에 도달하기 위한 핵심은 지식을 어디서 배웠는지
에 대한 지각적인 세부 정보들로부터 추상화된 개념적 지식
을 습득하는 것 ”
(2018, 딥마인드 공개 강연)
-구글 딥마인드 최고경영자
- 구글 딥마인드 창업자로 , 바둑 인공지능 '알파고 (AlphaGo)' 를 개발해 
인공지능 인식 대중화에 기여 데미스 하사비스
(Demis Hassabis)

## Page 8

4 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
     주목받는 인공지능 9대 핵심 기술Ⅱ
□ 인공지능 핵심 기술 및 시사점 도출 단계 및 프레임워크
o글로벌 주요 언론 ,학회 ,컨설팅 기업 등 인공지능 주요 인사의 
인터뷰 내용을 기반으로 향후 주목하는 인공지능 기술 도출 
①1단계 :글로벌 주요 언론 ,컨설팅 기업 등의 자료를 종합 분
석하여 향후 인공지능 산업의 미래 전망 분석
②2단계 :자료 분석을 통해 9대 핵심 기술 도출
③3단계 :9대 핵심 기술들이 국내 인공지능 산업에 조기 정착할 
수 있도록 기술 활용 분야 정리 및 시사점 도출
< 주목할 AI 9대 핵심 기술 > 


## Page 9

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 5
IT & Future Strategy(1 호)  2020. 1□ 인공지능 9대 핵심 기술 및 활용 방안
인공지능 9대 핵심 기술 향후 기술의 수용(활용) 모습(안)
 GPT-3
‘GPT-3 의 등장 및 언어모델의 스케일업 ’➡. 빅테크기업 : 모델 자체 개발 및 
유료 API 서비스 제공
. 스타트업 : API 활용 서비스 개발 
또는 빅테크기업 AI모델 응용
 연합학습 (Federated Learning)
‘민감정보가 보호되는 분산 AI 학습’➡병원 등 민감데이터 보유기관 간 
시범사업 및 기술 검증
 
 엣지 AI
‘온디바이스 AI를 위한 모델 경량화 ’➡ 클라우드 활용 없이 스마트폰 , 
AI비서 등 단말기 내에서 AI 실행 
 트랜스포머 (Transformer)
‘NLP의 트랜스포머가 컴퓨터 비전까지 확대’➡시각지능 (컴퓨터비전 ) 분야에도 
트랜스포머 기술이 내장
 시스템 2 AI(System2 AI)
‘단순 이해를 넘어 인과적 관계를 이해’➡직관적 사물 인식 등을 넘어 맥락을 
이해하는 인공지능이 산업 내 적용
 자기지도학습 (Self supervised learning)
‘데이터 라벨링의 한계를 극복’➡자연어처리 분야의 적용을 넘어 
컴퓨터 비전분야에서도 적용 활발
 생성적 AI(Generative AI)
‘인식(판별)을 위한 AI를 넘어 창조하는 AI’➡데이터 증강 등을 활용해 
원본데이터의 부족함을 보충 
 전이학습 (Transfer learning)
‘누구나 딥러닝을 할 수 있도록 지원’➡사전 학습된 모델을 활용하여 , 
산업에 필요한 맞춤형 모델 재생산
 Auto ML
‘AI도 AI가 만들어 낸다’➡인공지능 모델 개발 시 
발생하는 반복‧비효율적인 작업은 
인공지능을 활용

## Page 10

6 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
 초대규모 모델 GPT-3  “GPT-3 의 등장 및 언어모델의 스케일업 ”
o글로벌 테크 기업들은 앞다투어 대규모 모델을 개발하여 성능을 
향상시키고 있으며 ,최근에는 초대규모 모델 GPT-3가 공개 (‘20.6)
-오픈 AI3)에서는 기존 MS에서 공개했던 Turing LNG*보다 약
10배 정도 더 큰 GPT-3를 공개하면서 시장에 큰 파장을 불러옴 
     * Turing NLG(170 억개 매개변수 ) → GPT-3(1,750 억개 매개변수 )
< 언어모델의 사이즈 추세 > 
※ 자료 : State of AI 2020
o시장은 초대규모 모델의 우수한 성능을 인지하기 시작했으며 ,초
대규모 모델은 API제공 등 비즈니스 플랫폼 형태로 진화할 전망
-많은 정보를 학습한 초대규모 모델은 기존 모델 대비 범용성이 
확장된 것을 보여줬으며 ,시장은 초대규모 모델의 중요성 인지
     ※ NAVER 는 GPT-3 를 능가할 초대형 (한국어 , 일본어 ) 모델 개발 선언(’20.10)
-또한,GPT-3는 베타서비스로 API를 통해 수많은 AI서비스를 개발
할 수 있도록 지원하는 등 AI모델에서 플랫폼의 역할로 진화 중
o향후 AI모델 성능 향상을 위해 글로벌 테크 기업들은 슈퍼컴
퓨팅 기반의 초대규모 AI모델을 지속적으로 개발할 전망
3) 테슬라 CEO 일론 머스크 , 전 Y 컴비네이터 회장 샘 알트맨이 설립한 범용 인공지능을 위한 연구소

## Page 11

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 7
IT & Future Strategy(1 호)  2020. 1참고 초대규모 모델 GPT-3 와 퓨샷러닝
 Ÿ 오픈AI에서 “Language models are few-shot learner” 라는 논문을 발표하며 , 
GPT-3 모델을 전 세계에 공개(‘20.6)
  - GPT-3 는 기존에 공개된 마이크로소프트의 Turing-LNG 보다 모델의 사이즈가 
10배 이상 큰 1,750억개의 매개변수를 가진 초대규모 모델
  - 학습에 활용된 데이터 (단어)는 크롤링 (4,100억개), 웹텍스트 (190억개), 책1(120
억개), 책2(550억개), 위키피디아 (30억개)로 초대규모 데이터셋
 Ÿ 논문 제목에서 추측할 수 있듯이 , 초대규모 모델인 GPT-3 는 퓨샷러닝에서 
우수한 성능을 나타내고 있음을 강조
< 원샷러닝 > < 퓨샷러닝 >
  - (원샷러닝 ) GPT-3 와 같은 범용성 높은 언어모델에 하나의 예시만 주어지고 
번역 등 원하는 Task를 해결하도록 하는 방식
  - (퓨샷러닝 ) 원샷러닝은 하나의 예시만 주어졌으나 , 퓨샷러닝은 두 개 이상의 
예시를 주며, 모델이 몇 가지의 사례를 이해하고 번역 등 Task 수행
 Ÿ 타 모델의 미세조정 (Fine-tuning)* 으로 재학습된 최고 신기록을 GPT-3 모델
은 퓨샷러닝을 통해 경신하는 등 우수한 성능 보여주고 있음
   * 퓨샷러닝은 소량의 데이터로 모델의 재학습시키는 것이지만 , 미세조정은 퓨샷러
닝보다는 많은 Task 데이터로 모델을 재학습하는 것을 의미
  
※ 자료 : Language models are few-shot Learner( 오픈AI,2020.5)

## Page 12

8 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
 연합학습 (Federated Learning)  “개인정보가 보호되는 분산 AI 학습”
oAI모델 학습시 데이터를 통합 ‧
이동하면서 발생할 수 있는 개인
정보보호 이슈의 부담을 완화할 수 있는 연합학습 개념이 부상
-데이터 활용의 증가는 A I산업의 발전을 이끄는 반면 필연적으로 개인정보 
보호 이슈가 발생하며 ,이러한 제약으로 인해 A I성능 향상에 한계 존재
-연합학습은 데이터를 중앙에 모아서 학습하는 기존의 통합학습과 달리 
각 기관 (기기)에서 학습한 모델의 가중치만 중앙으로 취합하는 방식
o‘16년 구글에서 연합학습을 발표한 이후 관련 연구가 폭발적으로 
증가하고 있으며 글로벌 테크 기업도 적극적인 연구 개발 착수
    ※ 구 글 은  스 마 트 폰 을  연 합 학 습 에  참 여 시 켜  G-board 의  성 능  향 상 을  위 해  적 용  (구글IO, 2017)
<연합학습 개요> < 연합학습 관련 논문 증가 추세>
 
※ 자료 : 구글 AI
※ 자료 : 구글 AI 
o특히 환자의 민감한 개인정보 보호가 중요한 의료 분야에서 대규모 
정밀 의학을 가능하게 하는 요소로써 적극 도입되는 추세
    ※ 엔비디아 (NVIDIA) 는 환자 데이터 공유 없이 로컬에서 학습을 진행하고 다른 병원 등과 
협력 가능한 '엔비디아 클라라 연합학습 (NVIDIA Clara Federated Learning)' 공개(’19.2)
-분산된 데이터를 활용하여 엄격한 규제 문제를 해소하며 필요한 의
료 분야 전체 스펙트럼을 포괄하는 대규모 데이터베이스 구축 가능 
-데이터 풀 확대로 기존에 연구가 어려웠던 희귀질환 모델 구축 ,
신약 개발을 통한 출시 시간 단축 등 다양한 혁신 기회 창출

## Page 13

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 9
IT & Future Strategy(1 호)  2020. 1참고 연합학습 (Federated Learning) 개념
Ÿ 구글은 2017년 구글IO 세미나를 통해 분산된 디바이스에서 각각 학습을 
하여, 모델의 가중치만 중앙 서버로 전달하는 연합학습의 개념 소개
 - 데이터의 이동 없이 분산 학습이 가능하므로 , 개인정보보호 이슈 및 컴퓨팅
파워의 효율적 운영에 대한 해결책으로 부상
< 연합학습의 학습 순서 설명 >
①
 ②
 ③
①~⑤번 반복
⑤
 ④
① 서버에서 보유한 데이터로 학습하여 기본적인 모델 생성
② 생성된 기본 모델을 여러 클라이언트에게 배포
③ 클라이언트는 보유한 데이터를 활용하여 모델 업데이트
④ 업데이트된 모델의 파라미터 값을 서버로 전송하고 , 클라이언트로부터 
전달받은 파라미터를 통해 서버는 새롭게 모델 업데이트
⑤ 업데이트된 모델을 클라이언트에게 다시 전송
⑥ 반복                      ※ 자료 : Federated learning 개념(허민석 -유튜브 )
Ÿ NVIDIA 는 데이터 이동관련 개인정보보호 이슈를 해결하면서 , 방대한 양의 의료 데
이터를 활용하기 위해 연합학습 플랫폼을 개발하여 의료 이미지 분석 서비스 지원
<연합학습 (Federated Learning)> <연합학습 결과 활용(의료진단 )>
※ 자료 : Federated learning Clara platform(NVIDIA) 
※ 자료 : AI 활성화를 위한 3대 자원 지원 전략(한국지능정보사회진흥원 , 2020) 

## Page 14

10 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
 엣지 AI(Edge AI) “온디바이스 AI를 위한 모델 경량화 ”
o클라우드가 글로벌 트렌드로 자리 잡은 상황에서 ,클라우드의 중앙 
집중식 관리 한계를 극복하기 위한 방안으로 엣지 AI도입 확대
-전통적으로 빅데이터 ‧
AI서비스는 추론 (예측 )시 발생하는 연
산량의 한계 때문에 클라우드 환경에서 서비스 제공
      ※ AI 데이터의 약 91%는 중앙 집중식 데이터 센터에서 처리(Gartner, ‘18.10)
-최근 추론 (예측)시 발생하는 지연속도에 민감한 서비스들이 많아
짐에 따라 디바이스 내에서 연산하는 엣지 AI가 주목받고 있음
o엣지 AI는 데이터 이동이 발생하지 않으므로 중앙집중식 처리에
서 발생하는 비용 ,속도 ,데이터 프라이버시 등의 단점 보완 가능
-현재 데이터 보안상의 문제로 접근이 불가능한 수많은 로컬 데이
터에 자유롭게 접근 가능하므로 다양한 응용 서비스 창출 기대
< 엣지 AI 장점>
분야 내용
보안(Security)-데이터를 주고받지 않고 로컬 장치에서 처리가 가능하므로 데이터 
프라이버시 이슈에서 자유로워 , 기업은 차별화된 개인 서비스 기
능 제공 가능
높은 응답성
(Highly Responsive)-여러 개의 네트워크 노드에서 실행 가능해 , 데이터와 프로세싱 간 
물리적 거리를 좁혀 병목현상을 줄이고 애플리케이션 속도 가속화 
비용 절감
(Reduced Costs)-데이터를 전송하기 위한 통신망과 높은 대역폭이 불필요하므로 
해당 비용이 절감되는 효과
※ 자료 : MC.AI, NVIDIA, BMT 자료 취합 후 정리
o다만 적은 메모리와 계산 능력을 보유한 엣지 장치 (스마트폰 ,차량,드론 
등)의 한계를 극복하고 AI구현을 하기 위한 신기술 개발이 핵심 이슈
-특히 성능 저하 없이 모델 크기를 압축하는 기술 방안이 주요 이슈
이며 가지치기 *,양자화 **등의 기술이 주된 해결책으로 논의
    * 가치치기 : 신경망에서 중요도가 낮은 가중치를 제거, 작은 모델로 재훈련
    ** 양자화  : 값을 표현하기 위해 더 적은 비트수를 사용하여 모델 압축

## Page 15

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 11
IT & Future Strategy(1 호)  2020. 1 트랜스포머 (Transformer)  “NLP에서 컴퓨터 비전까지 영역 확장”
o트랜스포머는 언어처리의 병렬화를 통해 계산 효율성 향상 등 
그간 순차적으로 단어를 학습하는 알고리즘의 한계를 극복
-트랜스포머 (구글 ,2017)가 등장하기 이전에는 데이터를 순차적으
로(단어의 순서 )처리하는 순환신경망 (RNN 4))방식을 활용
-트랜스포머의 병렬화로 인해 대규모 데이터셋을 학습할 수 
있게 되었고 ,GPT-3의 경우 약 5천억 토큰 (단어 )들로 훈련
o트랜스포머 공개 이후 글로벌 테크 기업들은 모두 트랜스포머 
기반의 언어모델을 앞다투어 연구하고 공개하기 시작
-언어모델의 표준처럼 불리는 구글의 BERT 5),오픈 AI의 GPT 6)
등은 트랜스포머 기반으로 개발된 언어모델
-현재는 대부분의 언어모델이 BERT, GPT의 사전학습모델을 
활용하여 ,각 과제 (Task)를 수행하는 모델을 생산하는 형태
o컴퓨터 비전 분야는 2012년 이후 전통적으로 CNN 7)기법을 활용해 ,
모델을 개발해왔으나 최근 NLP의 트랜스포머 방식 도입 연구 중
-2012년 이미지넷 챌린지에서 알렉스넷 8)(CNN기법 )등장 후 컴
퓨터 비전 분야는 주로 CNN을 활용하여 모델 개발
-2020년 하반기 ,컴퓨터 비전 분야는 전통적인 CNN방식을 벗
어나 ,트랜스포머를 적용하여 괄목할만한 성능을 내고 있음
-향후 트랜스포머는 NLP뿐만 아니라 ,컴퓨터 비전 분야에서도 세
계 최고 수준의 AI성능을 제시하는 연구 성과 발표가 기대됨
4) RNN(Recurrent neural network) : 인공신경망의 한 종류로 , 유닛 간의 연결이 순환적 구조를 갖는 특징 보유
5) BERT(Bidirectional Encoder Representations from Transformers) : 구글에서 개발한 자연어처리 (NLP) 모델
6) GPT(Generative pretraining transformer) : 오픈AI에서 개발한 자연어처리 모델 
7) CNN(Convolutional neural network) : 시각적 영상을 분석하는 데 사용되는  인공신경망의 하나의 방법
8) AlexNet : 2012년에 개최된 이미지넷 챌린지에서 최초로 딥러닝을 도입할 때, 사용된 알고리즘

## Page 16

12 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
 시스템 2 AI(System2 AI) “단순 이해를 넘어 인과적 이해를 하는 AI”
o인공지능이 단순 인식이 가능한 ‘시스템 1’수준에서 인과관계 
파악이 가능한 ‘시스템 2’수준으로의 이동을 위한 연구 활발
      ※ ‘시스템 1’ 사고: 주변 인식, 직감적 위험 회피 등과 같이 인간이 무의식적
으로 처리 가능한 과정으로 , 뇌의 빠르고 자동적인 접근 방식 
      ※ ‘시스템 2’ 사고: 추상적인 문제를 다루거나 새로운 상황을 처리하기 위한 
추론이 필요할 때 주로 사용되는 분석적인 과정
-요슈아 벤지오 (Yoshua Bengio)는 인공지능이 학습되지 않은 상
황에서도 맥락을 이해하는 ‘시스템 2’추론 중요성을 강조
      ※ 최근 단순한 인과관계 인식이 가능한 딥러닝 접근 방식을 설명한 논문 발표(‘19.1)
-그리고 인과관계에 대한 추론 영역의 성능 향상 없이는 인간
지능 수준의 접근은 어려울 것이라고 언급
o인공지능의 기대에 비해 현재 인공지능 시스템은 활용 분야가 
제한적이고 인과관계 설명이 불충분한 점 등 한계 보유
-이미지에서 고양이를 인식하거나 음성 명령을 인식하는 것과 같이 
‘시스템 1’사고적인 작업에 대해서만 구체적이고 뛰어난 성능 발휘
-인공지능은 근본적으로 원인과 결과를 알 수 없는 블랙박스가 
있어 처리 과정의 설명이 중요한 상황에서 활용이 어려움
      ※ 인공지능이 학습할 때 입력 변수는 수십, 수백 단계의 변형을 거쳐서 최종 모
델에 반영되므로 , 입력 변수와 결과의 직접적인 관계 추적이 어려운 상황
      ※ 의 료  분 야 의  경 우  질 병  진 단 의  결 과 가  어 떤  과 정 을  거 쳤 는 지  파 악 이  안  되 므 로  활 용 에  제 한
o인공지능 연구와 신경 과학 연구 분야가 서로 협력하여 발전
함으로써 ‘시스템 2’사고로의 진화가 이루어질 것이라 예상
-지난 10년간 인공지능은 뇌의 생각 방식을 모방해왔고 ,향후
에도 새로운 환경에서의 뇌 인지과정의 모방이 이루어질 전망
-‘시스템 2’추론이 가능해지면 학습 조건과 동일하지 않은 환경
(데이터 분포 )에서도 맥락을 이해하며 상황 대처가 가능 

## Page 17

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 13
IT & Future Strategy(1 호)  2020. 1 자기지도학습 (Self supervised learning)  “데이터 라벨링의 한계 극복”
o지도학습은 지난 10년 동안 자율주행차 ,음성 비서 등 인공지능 
분야에서 괄목할만한 발전을 주도했으나 ,심각한 한계도 존재
-지도학습의 원천이 되는 데이터를 수작업으로 라벨링을 해야하는 
번거로움과 비용 부담이 발생하므로 인공지능 개발의 주요 한계
-지도학습은 주어진 데이터셋에 포함된 함축된 정보 ,관계 및 의
미를 탐색하는 대신 연구자들이 미리 식별한 개념과 범주에 의존
o얀 르쿤은 비지도 학습의 의미적 모호성 때문에 자기지도학습이라 
명명하고 ,향후 자기지도학습이 미래 AI혁신을 주도할 것이라 전망
-얀 르쿤은 현재 비지도학습 방법이 ,실제 지도 (supervision) 가 
없는 것이 아니므로 의미적 모호성 발생한다고 언급
-자기지도학습은 입력 값의 일정 부분으로 입력 값의 다른 부분
을 예측하며 ,입력 값의 자체로 지도 (supervision) 를 만들어 학습
-2020년 초 제프리 힌튼 교수는 컴퓨터 비전 분야에서 지도학
습의 성능에 준하는 자기지도학습 연구 성과를 발표 
     ※ SimCLR 모델은 이미지넷 Top-1 정확도에서 지도학습의 성능에 근접
     ※ 언어모델은 자기지도학습을 활용하여 모델을 생성(BERT, GPT-3 등)
<가트너 , Emerging tech 2020> <이미지 분야 자기지도학습 성능>
※ Hype Cycle for Emerging Tech. 2020(Gartner) ※ SimCLR v2 논문 (‘20.6,구글(제프리힌튼 ))
o향후 데이터 라벨링 등 AI모델링 전 발생하는 노동집약적인 
비효율 문제를 개선하기 위해 자기지도학습이 주목받을 전망

## Page 18

14 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
 생성적 AI(Generativa AI) “(사물 등) 인식을 위한 AI가 아닌 창조를 하는 AI”
o인공지능이 텍스트 ,이미지 등 기존 콘텐츠를 사용해 자체적으로 
새로운 콘텐츠를 만드는 생성적 AI(Generative AI)분야가 빠르게 성장
-인공지능이 단순히 인지 (판별)하는 것을 넘어 입력된 학습 데이
터의 패턴을 익혀 해당 데이터 분포와 유사한 콘텐츠를 생성 
-2014년 이안 굿펠로우 (Ian Goodfellow) 가 소개한 변증법적 인공지능 
알고리즘 ‘생성적 적대 신경망 (GAN)’이 대표적 핵심 기술
    ※ GAN(Generative Adversarial Network) : 실제 데이터와 유사하게 새로운 
것을 만들어내는 생성자와 만들어진 것을 평가하는 판별자가 끊임없이 서로 
대립하며 성능을 개선해나가는 방식
<생성적 AI 예시>
 
※ 자료 : If Picasso Were to Paint The Mona Lisa (Ali Khosh, ‘19.10)
o인공지능 모델을 학습할 때,부족한 데이터셋을 인위적으로 
생성하는 데이터 증강 (Data Augmentation) 분야에 활용
-데이터의 클래스 (개,비행기 ,자동차 )의 불균형으로 인해 데이터의 
추가적인 확보가 필요할 때,GAN을 활용하여 부족한 데이터 생성 
-또한 원본 데이터에 민감한 정보가 포함된 경우 ,GAN을 통해 
합성 데이터를 생성하여 민감한 정보를 우회
o다만 ,악용될 경우 사회적으로 부정적인 영향을 미칠 우려가 
있으므로 기술의 양면성 및 잠재적 파급력에 대한 논의 확산
-유명인·정치인을 대상으로 한 딥페이크 영상,생체 인식 데이터 위조 
등 윤리적 측면에서 부정적인 영향을 대비하기 위한 방안 마련 필요 

## Page 19

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 15
IT & Future Strategy(1 호)  2020. 1 전이학습 (Transfer learning)  “누구나 딥러닝을 할 수 있는 환경 확산”
o전이학습 (Transfer learning)은 기존에 학습된 모델의 신경망 일부
를 재학습 하여 원하는 Task에 맞는 모델을 재생성하는 방법
-원하는 Task에 대한 데이터가 부족하거나 ,컴퓨팅 자원의 효
율적 활용을 위해 기존 모델을 재활용하여 학습
-기업에서 인공지능 모델 개발 시 데이터 부족 ,컴퓨팅 자원 부족 
등의 한계를 극복할 수 있도록 지원하는 응용 기술 (Gartner )
<전이학습의 효율성 > <일반 AI 모델 학습과 전이학습의 차이>
※H andbook O f Research O n M L Applications and Trends 
o최근 트렌드는 글로벌 테크 기업들이 컴퓨팅 성능을 바탕으로 
성능 좋은 모델을 공개하면 ,그 모델을 미세 조정하여 사용
     ※ 구글-Big transfer( 컴퓨터 비전), BERT(언어 모델), 오픈AI-GPT 모델
-사업 초기 단계 ,마이크로서비스 개발 시 경제성 ‧
효율성 측면을 
고려하여 ,중소 ‧
스타트업들은 기존 모델을 전이학습하여 개발
     ※ 전이 학습을 통해 파일럿이 검증되고 , 타당성 검증 후 본 서비스 개발
-GPT-3는 API를 통해 수많은 인공지능 서비스를 개발할 수 
있도록 지원하는 등 인공지능 모델에서 플랫폼의 역할로 진화 중
o허깅 페이스 9)에서는 각종 인공지능 모델이 저장된 모델 허브를 
운영하며 ,개발자들이 쉽게 전이학습을 할 수 있도록 지원 중
9) 허깅 페이스 (Hugging Face) 모델 허브: 언어, 비전 등 AI 모델을 사용자가 쉽게 사용할 수 있도록 지원

## Page 20

16 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
참고 전이학습 (Transfer learning) 과 구글 티처블 머신
 Ÿ 전이학습은 데이터의 양이 충분하지 않을 때, 사전에 훈련(학습)된 모델을 활
용하여 , 은닉층 일부만을 재학습 시켜 원하는 Task의 목표를 달성하는 기법
  - 예를 들어, 이미지를 분류 할 때, 이미지넷 전체 데이터를 통해 학습한 기본 
모델을 활용하여 , 이미지넷에는 없는 이미지를 선별할 때 활용
  ※ 산업별 기자재 (볼트, 너트 등) 분류 모델 생성 시 전이학습 활용 가능
< 전이학습 (Transfer learning) 의 구조 >
 Ÿ 구글에서 제공하고 있는 Teachable machine 이 전이학습 과정을 자동으로 처
리해주는 서비스이며 , 쉽게 AI를 구현할 수 있는 Tool로 유명
  - 대량의 학습 데이터를 MobileNet 알고리즘으로 사전 훈련모델을 생성하고 , 
이 모델의 마지막 일부 Layer만 수정하여 전이학습 진행
  - 사용자들은 Teachable machine 툴로 자신에게 필요한 데이터를 입력하여 
학습시키고 누구나 쉽게 재미있는 서비스를 제작하고 있음
< Teachable machine 구조 > < 마이크로서비스 제작(포즈 인식) >
※ 자료 : AI 활성화를 위한 3대 자원 지원 전략(한국지능정보사회진흥원 , 2020)

## Page 21

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 17
IT & Future Strategy(1 호)  2020. 1 AutoML  “AI도 AI가 만들어 낸다”
o머신러닝 개발 과정에서 소모적이고 반복되는 작업을 자동화하는 
프로세스인 AutoML (Automated machine learning)의 지속적 부상
-현재 인공지능 개발을 위해서는 지속적으로 발생하는 데이터 
관리 ,모델 학습 및 관리 등 많은 자원과 시간이 필요 
-AutoML은 노동집약적 과정인 머신러닝 모델 개발 작업의 상당 
부분을 자동화하며 모델 개발자의 개입을 최소화
    ※ ML 표준 작업 과정 : 데이터 수집→점검 및 탐색→전처리→모델링 및 훈련→평가→배포
oAutoML 의 최적의 알고리즘 선정 등을 통해 모델의 성능 향
상을 도모할 수 있고 ,효율적으로 머신러닝 모델 구축 가능
-AutoML은 모델의 성능 최적화 관점에서 데이터의 특징 추출 ,
최적의 알고리즘 아키텍처 구성 ,초매개변수 설정 등으로 구성
-AutoML의 수행 영역은 숙련된 데이터 과학자가 수행하는 영역
이므로 향후 데이터 과학 분야 인재 부족에 대한 대안으로 언급
<머신러닝 생애주기 중 AutoML 영역>
※ 자료 : AutoML 기술 동향(ETRI,‘19.8)
o3대 클라우드 10)플랫폼에서도 AutoML 솔루션을 제공하고 있
으며 ,기업의 수요도 빠르게 증가할 것으로 기대
10) 아마존 세이지메이커 (Amazon SageMaker), 마이크로소프트 에저(Microsoft Azure), 구글 클라우드 (Google Cloud)  

## Page 22

18 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
     인공지능 9대 핵심 기술로 본 주요 시사점Ⅲ
□ 인공지능 활성화를 위한 주요 시사점
o빠르게 발전하는 인공지능 기술을 산업 내 적절하게 적용하고 
활성화하기 위해 인공지능 핵심 기술 분석 및 시사점 도출 
-글로벌 주요 언론 ,컨설팅 기업의 자료와 인공지능 주요 인사의 
인터뷰 내용 등을 기반으로 향후 주목하는 인공지능 기술 도출
-9대 기술을 통해 모델의 대형화 ‧
경량화 ,응용서비스 활성화 
지원 기술 현황 ,우수인재의 중요성 등의 시사점 도출
< 인공지능 9대 핵심 기술 및 시사점 >


## Page 23

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 19
IT & Future Strategy(1 호)  2020. 1□ 인공지능 모델의 초대규모화가 시작
o트랜스포머의 등장으로 자연어처리 분야에서 순차적 학습
(RNN)에서 병렬 처리 (트랜스포머 )로 패러다임이 변화
-기존 알고리즘 대비 모델의 스케일업 및 병렬처리 등이 가능
해지면서 ,트랜스포머는 자연어처리 분야의 핵심 기술로 부상
-향후 BERT, GPT등 글로벌 주류 언어모델에서 트랜스포머 
기술 기반의 언어모델을 개발하여 ,후속 연구에 기여
-최근에는 이미지 처리 분야에서도 트랜스포머를 활용하여 성
능을 개선하는 등 NLP뿐만 아니라 이미지 분야 *로 확장 중
     * 구글-Visual Transformer(‘20), 페이스북 -DETR, DeiT(’20), 오픈AI-Image GPT(‘20)
o자기지도학습을 통한 AI모델은 비용‧
시간 측면에서 소모적인 업
무인 데이터 라벨링에서 벗어나 ,대규모 데이터에 대한 부담 완화 
-자기지도학습은 비지도학습의 방법으로 ,데이터 라벨링 없이 
원시 데이터를 통해 모델을 학습시키는 방법
-언어모델은 자기지도학습을 통해 언어에 대해 전반적으로 이
해하는 모델을 생성하고 ,완성된 모델을 각 과제해결에 활용
o트랜스포머의 병렬처리 ,자기지도학습의 대규모 데이터 활용 
등으로 인해 인공지능 모델은 지속적으로 대형화
-인공지능 언어모델의 사이즈와 대규모 데이터를 활용하여 ,초
대규모 모델인 GPT-3가 등장 
-GPT-3에서 퓨샷러닝 등 범용성에 대한 기술 수준의 향상을 
보여주며 ,‘20년 최고의 인공지능 성과로 업계에서 인정받음
-향후 GPT-4에서는 현재 1,750억개 매개변수를 넘어서서 ,인간 
뇌에 있는 뉴런의 개수만큼 커질 것으로 전망

## Page 24

20 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
□ 응용서비스 활성화를 위한 기반 기술이 부상
o법‧
제도적인 제약을 극복하기 위해 데이터의 이동 ‧
통합 과정 
없이 데이터를 학습할 수 있는 연합학습이 부상
-연합학습은 데이터를 학습할 때,각 기관에서 학습한 모델의 
매개변수를 공유하는 형태이므로 ,개인정보보호 규제 우회
-현재는 헬스케어 분야에서 글로벌 컨소시움을 형성하여 ,헬스
케어 데이터의 부족을 연합학습을 활용하여 해소 중
     ※ 글로벌 신약개발 플랫폼 (MELLODDY) : 세계 주요 제약회사 , 바이오 스타트업 , 
유럽 주요 대학이 참여해 구축한 연합학습 플랫폼
o산업현장에서 지연 없이 모델의 추론을 수행하기 위해 ,디바
이스에서 즉각적으로 추론 수행이 가능한 경량화 기술이 중요
-모델의 정확도를 개선하기 위해 데이터 및 모델 규모가 증가
하고 있으나 ,산업 현장에서 즉시 활용은 어려운 상황
-따라서 ,클라우드의 환경에서 벗어나 디바이스에서 인공지능을 
실행시키기 위한 모델 경량화도 동시에 진행 중
     ※ 고성능 모델이 등장하여 성능 기록을 경신하면 , 이와 같은 수준의 성능을 
기록하는 경량화 모델 연구가 병렬적으로 진행되고 있음
o데이터를 밑바닥 (from scratch)부터 학습하는 한계를 극복하기 
위해 기존 학습된 모델의 지식 (매개변수 값)을 활용하여 새로운 
목표 과제를 해결하는 전이학습이 보편화
-전이학습은 기존에 개발된 모델의 지식 (매개변수 값)을 활용하
여,새롭게 수행해야 할 과제에서 재활용하는 방식
-인공지능 모델 개발 시 데이터를 밑바닥 (from scratch)부터 학습하
는 것이 아니라 ,사전 학습된 모델을 활용해 데이터 및 컴퓨팅 
자원 한계를 극복하며 인공지능 모델을 개발하는 추세

## Page 25

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 21
IT & Future Strategy(1 호)  2020. 1□ 우수인재 확보와 모델 성능 평가를 위한 공통 기준이 중요
o인공지능 알고리즘의 경쟁력은 우수인재의 확보 여부가 가장 
중요한 부분이며 ,차세대 인공지능 개발을 위한 역량 확보 필요
-AutoML ,생성적 AI,시스템 2AI등 알고리즘 분야는 우수인재
에 의존적인 경향이 높기 때문에 ,인재 양성‧
확보는 여전히 중요
-또한 알고리즘 경쟁력을 위한 인재뿐만 아니라 ,초대규모 모델을 
학습하기 위한 기반인 슈퍼컴퓨팅에 대한 전문 인재도 중요
o글로벌 인공지능 생태계 내에서 우수인재들이 개발한 모델의 
성능을 명확히 평가받을 수 있는 리더보드 존재
     ※ 글로벌 언어모델 (BERT, GPT-3 등)은 GLUE, SuperGLUE 등 공통된 Task를 
통해 순위 경쟁이 가능했기 때문에 경쟁하면 성능이 향상됨
     ※ 컴퓨터 비전분야는 이미지넷 데이터를 통해 경쟁하며 , 모델의 성능 비교
-국내도 AI학습용 데이터를 활용한 모델의 성능 경쟁을 유도
하여 ,우수 알고리즘 개발 및 확산에 기여하는 문화 조성 필요
<상시 운영되는 모델 성능 평가 및 리더보드 구축(예시)>


## Page 26

22 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
참고 자료☞
[1] 한국지능정보사회진흥원 (NIA), “AI 활성화를 위한 3대 자원 지원 전략”, 2020.9.
[2] 한국지능정보사회진흥원 (NIA), “AI 학습용 데이터 사업의 실효성 향상을 위한 정책 
방향”, 2020.11. 
[3] 정보통신정책연구원 (KISDI), “인공지능 기술발전이 인재양성 정책에 주는 시사점 : 
AutoML 의 사례”, 2020.10.
[4] 한국전자통신연구원 (ETRI), “자동 기계학습 (AutoML) 기술 동향”, 2019.8.
[5] Nathan Benaich·Ian Hogarth, “State of AI Report 2020”, 2020.10.
[6] OpenAI, “Language models are few-shot Learner”, 2020.5.
[7] Google AI, “Federated Learning: Collaborative Machine Learning without Centralized 
Training Data”, 2017.4.
[8] Gartner, “Gartner Top 10 Strategic Technology Trends for 2020”, 2019.10. 
[9] Gartner, “Hype Cycle for Emerging Technologies, 2020”, 2020.7. 
[8] Ting Chen·Simon Kornblith·Kevin Swersky·Mohammad Norouzi·Geoffrey Hinton, “Big 
Self-Supervised Models are Strong Semi-Supervised Learners”, 2020.6.
[9] Emilio Soria Olivas, 「Handbook Of Research On Machine Learning Applications and 
Trends: Algorithms, Methods and Techniques 」, 2009.
[10] 관련 웹사이트 (Accessed Dec. 2020)
 - Forbes(2020.10.), “The Next Generation Of Artificial Intelligence”, https://www.forbes.com/si
tes/robtoews/2020/10/12/the-next-generation-of-artificial-intelligence/?sh=7bbca58559eb

## Page 27

주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 23
IT & Future Strategy(1 호)  2020. 1 - Forbes(2020.10.), “The Next Generation Of Artificial Intelligence (Part 2)”, https://www.
forbes.com/sites/robtoews/2020/10/29/the-next-generation-of-artificial-intelligence-part
-2/?sh=271081c47a30
 - MIT Technology Review(2020.11.), “AI pioneer Geoff Hinton: “Deep learning is going 
to be able to do everything”“, https://www.technologyreview.com/2020/11/03/101161
6/ai-godfather-geoffrey-hinton-deep-learning-will-do-everything/
 - Google AI Blog(2017.4.), “Federated Learning: Collaborative Machine Learning without 
Centralized Training Data”, https://ai.googleblog.com/2017/04/federated-learning-colla
borative.html
 - WIRED(2019.10.), ”An AI Pioneer Wants His Algorithms to Understand the 'Why'“, htt
ps://www.wired.com/story/ai-pioneer-algorithms-understand-why/
 - Gartner(2018.10.), ”What Edge Computing Means for Infrastructure and Operations L
eaders“, https://www.gartner.com/smarterwithgartner/what-edge-computing-means-for
-infrastructure-and-operations-leaders/

## Page 28

24 주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점
IT & Future Strategy 보고서
• 제1호(2021. 1. 15.)  「주목받는 인공지능 (AI) 9대 핵심 기술 분석 및 주요 시사점 」
1. 본 보고서는 방송통신발전기금으로 수행한 정보통신 ‧방송 연구개발 사업의 결과물
이므로 , 보고서의 내용을 발표할 때는 반드시 과학기술정보통신부 정보통신 ‧방송 연구
개발 사업의 연구결과임을 밝혀야 합니다 .
2. 본 보고서 내용의 무단전재를 금하며 , 가공‧인용할 때는 반드시 출처를 「한국지능정
보사회진흥원 (NIA)」이라고 밝혀 주시기 바랍니다 .
3. 본 보고서의 내용은 한국지능정보사회진흥원 (NIA)의 공식 견해와 다를 수 있습니다 .

